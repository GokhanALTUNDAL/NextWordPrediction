{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fde54c76fc144f21863fd616fc1397e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Cümle:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8fabbd02d57a4c10818144a40c3e0ca5",
            "placeholder": "Eksik cümlenizi buraya yazın",
            "style": "IPY_MODEL_b64190f95c1f41ffa1a9c1a21e7bd934",
            "value": ""
          }
        },
        "8fabbd02d57a4c10818144a40c3e0ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64190f95c1f41ffa1a9c1a21e7bd934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "623be7b98a284997873d8dc172244b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": false,
            "description": "Kelime Sayısı:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4f4d218645954c3d8b4121e0ad328781",
            "max": 10,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_0758caa8d240447ca03acd73034261d0",
            "value": 1
          }
        },
        "4f4d218645954c3d8b4121e0ad328781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0758caa8d240447ca03acd73034261d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "48926711156f4bbc89e9b365a13e0ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Tahmin Et",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_163d81b3820242ecbc3d8446a8233dbc",
            "style": "IPY_MODEL_0124f550372b4c3aafe3021e258bc266",
            "tooltip": "Tahmin Et"
          }
        },
        "163d81b3820242ecbc3d8446a8233dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0124f550372b4c3aafe3021e258bc266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0f55cb2f92e14c9792fe1194b9d041e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855fa549684842e1ab541dab877c8f23",
            "placeholder": "​",
            "style": "IPY_MODEL_a5a89274913d4c0581df1afcc9ec27d3",
            "value": "Tahmin Edilen Cümle: Ağ güvenliği dersinde firewall konfigürasyonu yapmayı öğrendiniz bakış tasarımlarımızı oluşturduk"
          }
        },
        "855fa549684842e1ab541dab877c8f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a89274913d4c0581df1afcc9ec27d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Gerekli Kütüphanelerin İçe Aktarılması:\n",
        "\n",
        "Bu bölümde, metin işleme, model oluşturma ve eğitim için gerekli kütüphaneler içe aktarılır"
      ],
      "metadata": {
        "id": "3wPjvHEW0AmR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KvuFVAc2z7D1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Veri Setinin Yüklenmesi ve Temizlenmesİ:\n",
        "\n",
        "file_path: Veri setinin dosya yolunu belirtir.\n",
        "\n",
        "Veri yükleme ve temizleme: Veriyi dosyadan okur, küçük harfe çevirir ve noktalama işaretlerini temizler"
      ],
      "metadata": {
        "id": "KDUemQPH0IpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/trveriset.txt'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = file.read()\n",
        "\n",
        "data = data.lower()\n",
        "data = re.sub(r'[^\\w\\s]', '', data)\n"
      ],
      "metadata": {
        "id": "qzt4sJoF0UG8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tokenizer Oluşturma ve Veri Setine Fit Etme\n",
        "\n",
        "data.split('\\n'): Veriyi satırlara böler.\n",
        "\n",
        "Tokenizer: Kelimeleri sayısal değerlere dönüştürmek için kullanılır."
      ],
      "metadata": {
        "id": "zHfkRjWg0eVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.split('\\n')\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n"
      ],
      "metadata": {
        "id": "uP1TZffO0vTu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Dizilere Çevirme ve Padding\n",
        "\n",
        "Kelime dizileri oluşturma: Her cümleyi sayısal değerlere dönüştürür.\n",
        "\n",
        "Padding: Tüm dizileri aynı uzunlukta yapar."
      ],
      "metadata": {
        "id": "4u0h1eih0yYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "for line in data:\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n"
      ],
      "metadata": {
        "id": "E5oWDWjl05Bj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Giriş (X) ve Çıkış (y) Değerlerini Ayırma\n",
        "\n",
        "X, y ayırma: Giriş ve çıkış verilerini ayırır.\n",
        "\n",
        "Kategorik dönüşüm: Çıkış verilerini kategorik formata çevirir."
      ],
      "metadata": {
        "id": "rD7pT4mS07X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "y = to_categorical(y, num_classes=vocab_size)\n"
      ],
      "metadata": {
        "id": "VN9ekCdr1CdF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Modeli Oluşturma ve Derleme\n",
        "\n",
        "Model katmanları: Embedding, LSTM ve Dropout katmanları eklenir.\n",
        "\n",
        "Model derleme: Model, categorical_crossentropy kaybı ve adam optimizer ile derlenir."
      ],
      "metadata": {
        "id": "Mwv6SgvP1HE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length-1))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "C7HMniRy1TLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0a4915-22ec-4016-8fce-1fea05fde09d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 17, 100)           562900    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 17, 150)           150600    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 17, 150)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5629)              849979    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1744079 (6.65 MB)\n",
            "Trainable params: 1744079 (6.65 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Callbacks Tanımlama\n",
        "\n",
        "ModelCheckpoint: En iyi modeli kaydeder.\n",
        "\n",
        "EarlyStopping: Eğitim sırasında kaybın iyileşmediği durumlarda erken durdurma sağlar."
      ],
      "metadata": {
        "id": "5EnnxIQF1UST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('model.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
        "callbacks_list = [checkpoint, early_stopping]\n"
      ],
      "metadata": {
        "id": "1AHD4m0Y1ZHK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Modeli Eğitme ve Eğitim Geçmişini Kaydetme\n",
        "\n",
        "Model eğitimi: Modeli eğitim verileri üzerinde eğitir ve eğitim geçmişini history nesnesine kaydeder.\n"
      ],
      "metadata": {
        "id": "kw-G9f1S1blf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, epochs=250, batch_size=128, callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "id": "VCRezf5U1cPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49a8c50-5004-45e3-d773-4482351d9113"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 7.4171 - accuracy: 0.0247\n",
            "Epoch 1: loss improved from inf to 7.41714, saving model to model.h5\n",
            "254/254 [==============================] - 19s 55ms/step - loss: 7.4171 - accuracy: 0.0247\n",
            "Epoch 2/250\n",
            " 15/254 [>.............................] - ETA: 1s - loss: 6.9005 - accuracy: 0.0250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "254/254 [==============================] - ETA: 0s - loss: 6.8633 - accuracy: 0.0273\n",
            "Epoch 2: loss improved from 7.41714 to 6.86327, saving model to model.h5\n",
            "254/254 [==============================] - 4s 16ms/step - loss: 6.8633 - accuracy: 0.0273\n",
            "Epoch 3/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 6.4127 - accuracy: 0.0410\n",
            "Epoch 3: loss improved from 6.86327 to 6.41266, saving model to model.h5\n",
            "254/254 [==============================] - 4s 15ms/step - loss: 6.4127 - accuracy: 0.0410\n",
            "Epoch 4/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 5.9636 - accuracy: 0.0595\n",
            "Epoch 4: loss improved from 6.41266 to 5.96363, saving model to model.h5\n",
            "254/254 [==============================] - 3s 11ms/step - loss: 5.9636 - accuracy: 0.0595\n",
            "Epoch 5/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 5.5958 - accuracy: 0.0935\n",
            "Epoch 5: loss improved from 5.96363 to 5.59581, saving model to model.h5\n",
            "254/254 [==============================] - 3s 12ms/step - loss: 5.5958 - accuracy: 0.0935\n",
            "Epoch 6/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 5.2747 - accuracy: 0.1342\n",
            "Epoch 6: loss improved from 5.59581 to 5.27466, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 5.2747 - accuracy: 0.1342\n",
            "Epoch 7/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 4.9918 - accuracy: 0.1811\n",
            "Epoch 7: loss improved from 5.27466 to 4.99178, saving model to model.h5\n",
            "254/254 [==============================] - 3s 11ms/step - loss: 4.9918 - accuracy: 0.1811\n",
            "Epoch 8/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 4.7340 - accuracy: 0.2287\n",
            "Epoch 8: loss improved from 4.99178 to 4.73399, saving model to model.h5\n",
            "254/254 [==============================] - 3s 11ms/step - loss: 4.7340 - accuracy: 0.2287\n",
            "Epoch 9/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 4.5058 - accuracy: 0.2682\n",
            "Epoch 9: loss improved from 4.73399 to 4.50579, saving model to model.h5\n",
            "254/254 [==============================] - 2s 10ms/step - loss: 4.5058 - accuracy: 0.2682\n",
            "Epoch 10/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 4.2991 - accuracy: 0.3031\n",
            "Epoch 10: loss improved from 4.50579 to 4.29906, saving model to model.h5\n",
            "254/254 [==============================] - 2s 10ms/step - loss: 4.2991 - accuracy: 0.3031\n",
            "Epoch 11/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 4.1014 - accuracy: 0.3292\n",
            "Epoch 11: loss improved from 4.29906 to 4.10137, saving model to model.h5\n",
            "254/254 [==============================] - 2s 10ms/step - loss: 4.1014 - accuracy: 0.3292\n",
            "Epoch 12/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 3.9332 - accuracy: 0.3566\n",
            "Epoch 12: loss improved from 4.10137 to 3.93117, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 3.9312 - accuracy: 0.3569\n",
            "Epoch 13/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 3.7814 - accuracy: 0.3725\n",
            "Epoch 13: loss improved from 3.93117 to 3.78138, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 3.7814 - accuracy: 0.3725\n",
            "Epoch 14/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 3.6426 - accuracy: 0.3914\n",
            "Epoch 14: loss improved from 3.78138 to 3.64256, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 3.6426 - accuracy: 0.3914\n",
            "Epoch 15/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 3.5154 - accuracy: 0.4090\n",
            "Epoch 15: loss improved from 3.64256 to 3.51540, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 3.5154 - accuracy: 0.4090\n",
            "Epoch 16/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 3.3998 - accuracy: 0.4193\n",
            "Epoch 16: loss improved from 3.51540 to 3.39981, saving model to model.h5\n",
            "254/254 [==============================] - 2s 10ms/step - loss: 3.3998 - accuracy: 0.4193\n",
            "Epoch 17/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 3.2884 - accuracy: 0.4344\n",
            "Epoch 17: loss improved from 3.39981 to 3.28858, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 3.2886 - accuracy: 0.4343\n",
            "Epoch 18/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 3.1931 - accuracy: 0.4437\n",
            "Epoch 18: loss improved from 3.28858 to 3.19306, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 3.1931 - accuracy: 0.4437\n",
            "Epoch 19/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 3.0944 - accuracy: 0.4577\n",
            "Epoch 19: loss improved from 3.19306 to 3.09575, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 3.0957 - accuracy: 0.4576\n",
            "Epoch 20/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 3.0139 - accuracy: 0.4650\n",
            "Epoch 20: loss improved from 3.09575 to 3.01391, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 3.0139 - accuracy: 0.4650\n",
            "Epoch 21/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.9347 - accuracy: 0.4747\n",
            "Epoch 21: loss improved from 3.01391 to 2.93473, saving model to model.h5\n",
            "254/254 [==============================] - 2s 10ms/step - loss: 2.9347 - accuracy: 0.4747\n",
            "Epoch 22/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.8544 - accuracy: 0.4827\n",
            "Epoch 22: loss improved from 2.93473 to 2.85438, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.8544 - accuracy: 0.4827\n",
            "Epoch 23/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.7918 - accuracy: 0.4871\n",
            "Epoch 23: loss improved from 2.85438 to 2.79185, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.7918 - accuracy: 0.4871\n",
            "Epoch 24/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.7236 - accuracy: 0.4966\n",
            "Epoch 24: loss improved from 2.79185 to 2.72357, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.7236 - accuracy: 0.4966\n",
            "Epoch 25/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 2.6577 - accuracy: 0.5027\n",
            "Epoch 25: loss improved from 2.72357 to 2.66013, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 2.6601 - accuracy: 0.5025\n",
            "Epoch 26/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.6055 - accuracy: 0.5078\n",
            "Epoch 26: loss improved from 2.66013 to 2.60555, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.6055 - accuracy: 0.5078\n",
            "Epoch 27/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 2.5467 - accuracy: 0.5152\n",
            "Epoch 27: loss improved from 2.60555 to 2.54755, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.5475 - accuracy: 0.5152\n",
            "Epoch 28/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 2.4873 - accuracy: 0.5217\n",
            "Epoch 28: loss improved from 2.54755 to 2.48823, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.4882 - accuracy: 0.5218\n",
            "Epoch 29/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.4454 - accuracy: 0.5262\n",
            "Epoch 29: loss improved from 2.48823 to 2.44536, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.4454 - accuracy: 0.5262\n",
            "Epoch 30/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.3918 - accuracy: 0.5337\n",
            "Epoch 30: loss improved from 2.44536 to 2.39181, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.3918 - accuracy: 0.5337\n",
            "Epoch 31/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.3480 - accuracy: 0.5359\n",
            "Epoch 31: loss improved from 2.39181 to 2.34802, saving model to model.h5\n",
            "254/254 [==============================] - 2s 10ms/step - loss: 2.3480 - accuracy: 0.5359\n",
            "Epoch 32/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 2.3083 - accuracy: 0.5445\n",
            "Epoch 32: loss improved from 2.34802 to 2.30774, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.3077 - accuracy: 0.5447\n",
            "Epoch 33/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 2.2581 - accuracy: 0.5465\n",
            "Epoch 33: loss improved from 2.30774 to 2.25816, saving model to model.h5\n",
            "254/254 [==============================] - 2s 10ms/step - loss: 2.2582 - accuracy: 0.5466\n",
            "Epoch 34/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.2155 - accuracy: 0.5552\n",
            "Epoch 34: loss improved from 2.25816 to 2.21547, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 2.2155 - accuracy: 0.5552\n",
            "Epoch 35/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.1735 - accuracy: 0.5599\n",
            "Epoch 35: loss improved from 2.21547 to 2.17346, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.1735 - accuracy: 0.5599\n",
            "Epoch 36/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.1437 - accuracy: 0.5617\n",
            "Epoch 36: loss improved from 2.17346 to 2.14368, saving model to model.h5\n",
            "254/254 [==============================] - 3s 11ms/step - loss: 2.1437 - accuracy: 0.5617\n",
            "Epoch 37/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 2.1033 - accuracy: 0.5688\n",
            "Epoch 37: loss improved from 2.14368 to 2.10509, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.1051 - accuracy: 0.5686\n",
            "Epoch 38/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.0648 - accuracy: 0.5752\n",
            "Epoch 38: loss improved from 2.10509 to 2.06477, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.0648 - accuracy: 0.5752\n",
            "Epoch 39/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 2.0325 - accuracy: 0.5789\n",
            "Epoch 39: loss improved from 2.06477 to 2.03246, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 2.0325 - accuracy: 0.5789\n",
            "Epoch 40/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.9973 - accuracy: 0.5828\n",
            "Epoch 40: loss improved from 2.03246 to 1.99733, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.9973 - accuracy: 0.5828\n",
            "Epoch 41/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.9698 - accuracy: 0.5856\n",
            "Epoch 41: loss improved from 1.99733 to 1.96984, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.9698 - accuracy: 0.5856\n",
            "Epoch 42/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 1.9357 - accuracy: 0.5901\n",
            "Epoch 42: loss improved from 1.96984 to 1.93542, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.9354 - accuracy: 0.5902\n",
            "Epoch 43/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.9089 - accuracy: 0.5939\n",
            "Epoch 43: loss improved from 1.93542 to 1.90891, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 1.9089 - accuracy: 0.5939\n",
            "Epoch 44/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.8803 - accuracy: 0.5998\n",
            "Epoch 44: loss improved from 1.90891 to 1.88032, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.8803 - accuracy: 0.5998\n",
            "Epoch 45/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.8474 - accuracy: 0.6028\n",
            "Epoch 45: loss improved from 1.88032 to 1.84739, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.8474 - accuracy: 0.6028\n",
            "Epoch 46/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.8232 - accuracy: 0.6042\n",
            "Epoch 46: loss improved from 1.84739 to 1.82317, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 1.8232 - accuracy: 0.6042\n",
            "Epoch 47/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.7970 - accuracy: 0.6104\n",
            "Epoch 47: loss improved from 1.82317 to 1.79795, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.7980 - accuracy: 0.6102\n",
            "Epoch 48/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.7705 - accuracy: 0.6151\n",
            "Epoch 48: loss improved from 1.79795 to 1.77062, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.7706 - accuracy: 0.6152\n",
            "Epoch 49/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.7472 - accuracy: 0.6166\n",
            "Epoch 49: loss improved from 1.77062 to 1.74713, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.7471 - accuracy: 0.6167\n",
            "Epoch 50/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.7175 - accuracy: 0.6229\n",
            "Epoch 50: loss improved from 1.74713 to 1.71890, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.7189 - accuracy: 0.6225\n",
            "Epoch 51/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.7021 - accuracy: 0.6233\n",
            "Epoch 51: loss improved from 1.71890 to 1.70210, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.7021 - accuracy: 0.6233\n",
            "Epoch 52/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.6708 - accuracy: 0.6263\n",
            "Epoch 52: loss improved from 1.70210 to 1.67201, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.6720 - accuracy: 0.6262\n",
            "Epoch 53/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 1.6535 - accuracy: 0.6284\n",
            "Epoch 53: loss improved from 1.67201 to 1.65348, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.6535 - accuracy: 0.6285\n",
            "Epoch 54/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.6389 - accuracy: 0.6321\n",
            "Epoch 54: loss improved from 1.65348 to 1.63939, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.6394 - accuracy: 0.6321\n",
            "Epoch 55/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 1.6090 - accuracy: 0.6361\n",
            "Epoch 55: loss improved from 1.63939 to 1.61100, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.6110 - accuracy: 0.6356\n",
            "Epoch 56/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.5833 - accuracy: 0.6417\n",
            "Epoch 56: loss improved from 1.61100 to 1.58605, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.5861 - accuracy: 0.6411\n",
            "Epoch 57/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 1.5682 - accuracy: 0.6423\n",
            "Epoch 57: loss improved from 1.58605 to 1.56825, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.5682 - accuracy: 0.6425\n",
            "Epoch 58/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 1.5505 - accuracy: 0.6452\n",
            "Epoch 58: loss improved from 1.56825 to 1.55429, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.5543 - accuracy: 0.6446\n",
            "Epoch 59/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.6485\n",
            "Epoch 59: loss improved from 1.55429 to 1.53563, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.5356 - accuracy: 0.6483\n",
            "Epoch 60/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.5164 - accuracy: 0.6482\n",
            "Epoch 60: loss improved from 1.53563 to 1.51644, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.5164 - accuracy: 0.6482\n",
            "Epoch 61/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.4996 - accuracy: 0.6527\n",
            "Epoch 61: loss improved from 1.51644 to 1.50046, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.5005 - accuracy: 0.6528\n",
            "Epoch 62/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 1.4754 - accuracy: 0.6555\n",
            "Epoch 62: loss improved from 1.50046 to 1.47443, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.4744 - accuracy: 0.6557\n",
            "Epoch 63/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.6583\n",
            "Epoch 63: loss improved from 1.47443 to 1.46418, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.4642 - accuracy: 0.6583\n",
            "Epoch 64/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.4474 - accuracy: 0.6603\n",
            "Epoch 64: loss improved from 1.46418 to 1.44744, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.4474 - accuracy: 0.6603\n",
            "Epoch 65/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 1.4296 - accuracy: 0.6655\n",
            "Epoch 65: loss improved from 1.44744 to 1.42937, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.4294 - accuracy: 0.6656\n",
            "Epoch 66/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.4107 - accuracy: 0.6658\n",
            "Epoch 66: loss improved from 1.42937 to 1.41070, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.4107 - accuracy: 0.6658\n",
            "Epoch 67/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.3976 - accuracy: 0.6671\n",
            "Epoch 67: loss improved from 1.41070 to 1.39906, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.3991 - accuracy: 0.6669\n",
            "Epoch 68/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.3818 - accuracy: 0.6700\n",
            "Epoch 68: loss improved from 1.39906 to 1.38181, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.3818 - accuracy: 0.6700\n",
            "Epoch 69/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 1.3646 - accuracy: 0.6729\n",
            "Epoch 69: loss improved from 1.38181 to 1.36495, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.3649 - accuracy: 0.6728\n",
            "Epoch 70/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.3490 - accuracy: 0.6738\n",
            "Epoch 70: loss improved from 1.36495 to 1.34814, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.3481 - accuracy: 0.6740\n",
            "Epoch 71/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.3383 - accuracy: 0.6753\n",
            "Epoch 71: loss improved from 1.34814 to 1.33695, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.3369 - accuracy: 0.6757\n",
            "Epoch 72/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.3213 - accuracy: 0.6801\n",
            "Epoch 72: loss improved from 1.33695 to 1.32126, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.3213 - accuracy: 0.6801\n",
            "Epoch 73/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.3045 - accuracy: 0.6836\n",
            "Epoch 73: loss improved from 1.32126 to 1.30453, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.3045 - accuracy: 0.6836\n",
            "Epoch 74/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.3007 - accuracy: 0.6828\n",
            "Epoch 74: loss improved from 1.30453 to 1.30066, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.3007 - accuracy: 0.6828\n",
            "Epoch 75/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.2879 - accuracy: 0.6846\n",
            "Epoch 75: loss improved from 1.30066 to 1.28823, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.2882 - accuracy: 0.6845\n",
            "Epoch 76/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 1.2698 - accuracy: 0.6840\n",
            "Epoch 76: loss improved from 1.28823 to 1.26811, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.2681 - accuracy: 0.6844\n",
            "Epoch 77/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 1.2626 - accuracy: 0.6877\n",
            "Epoch 77: loss improved from 1.26811 to 1.26139, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.2614 - accuracy: 0.6883\n",
            "Epoch 78/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 1.2412 - accuracy: 0.6930\n",
            "Epoch 78: loss improved from 1.26139 to 1.24139, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.2414 - accuracy: 0.6930\n",
            "Epoch 79/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.2372 - accuracy: 0.6911\n",
            "Epoch 79: loss improved from 1.24139 to 1.23674, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.2367 - accuracy: 0.6912\n",
            "Epoch 80/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 1.2289 - accuracy: 0.6903\n",
            "Epoch 80: loss improved from 1.23674 to 1.22878, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.2288 - accuracy: 0.6906\n",
            "Epoch 81/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.2091 - accuracy: 0.6963\n",
            "Epoch 81: loss improved from 1.22878 to 1.20991, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.2099 - accuracy: 0.6962\n",
            "Epoch 82/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.1986 - accuracy: 0.6962\n",
            "Epoch 82: loss improved from 1.20991 to 1.19800, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1980 - accuracy: 0.6963\n",
            "Epoch 83/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.1862 - accuracy: 0.7003\n",
            "Epoch 83: loss improved from 1.19800 to 1.18618, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1862 - accuracy: 0.7003\n",
            "Epoch 84/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 1.1740 - accuracy: 0.6992\n",
            "Epoch 84: loss improved from 1.18618 to 1.17788, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1779 - accuracy: 0.6984\n",
            "Epoch 85/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.1602 - accuracy: 0.7028\n",
            "Epoch 85: loss improved from 1.17788 to 1.16024, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1602 - accuracy: 0.7028\n",
            "Epoch 86/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.1569 - accuracy: 0.7045\n",
            "Epoch 86: loss improved from 1.16024 to 1.15692, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1569 - accuracy: 0.7045\n",
            "Epoch 87/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.1465 - accuracy: 0.7048\n",
            "Epoch 87: loss improved from 1.15692 to 1.14767, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1477 - accuracy: 0.7045\n",
            "Epoch 88/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.1377 - accuracy: 0.7073\n",
            "Epoch 88: loss improved from 1.14767 to 1.13766, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 1.1377 - accuracy: 0.7073\n",
            "Epoch 89/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 1.1255 - accuracy: 0.7082\n",
            "Epoch 89: loss improved from 1.13766 to 1.12556, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1256 - accuracy: 0.7081\n",
            "Epoch 90/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 1.1157 - accuracy: 0.7095\n",
            "Epoch 90: loss improved from 1.12556 to 1.11597, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1160 - accuracy: 0.7094\n",
            "Epoch 91/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.1091 - accuracy: 0.7121\n",
            "Epoch 91: loss improved from 1.11597 to 1.10914, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.1091 - accuracy: 0.7121\n",
            "Epoch 92/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 1.0982 - accuracy: 0.7128\n",
            "Epoch 92: loss improved from 1.10914 to 1.09809, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0981 - accuracy: 0.7128\n",
            "Epoch 93/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.7110\n",
            "Epoch 93: loss improved from 1.09809 to 1.09585, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0958 - accuracy: 0.7110\n",
            "Epoch 94/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.0875 - accuracy: 0.7130\n",
            "Epoch 94: loss improved from 1.09585 to 1.08825, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0883 - accuracy: 0.7127\n",
            "Epoch 95/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.0753 - accuracy: 0.7177\n",
            "Epoch 95: loss improved from 1.08825 to 1.07466, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0747 - accuracy: 0.7179\n",
            "Epoch 96/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 1.0680 - accuracy: 0.7176\n",
            "Epoch 96: loss improved from 1.07466 to 1.06873, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0687 - accuracy: 0.7175\n",
            "Epoch 97/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 1.0564 - accuracy: 0.7179\n",
            "Epoch 97: loss improved from 1.06873 to 1.05642, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.0564 - accuracy: 0.7180\n",
            "Epoch 98/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.0430 - accuracy: 0.7204\n",
            "Epoch 98: loss improved from 1.05642 to 1.04307, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.0431 - accuracy: 0.7205\n",
            "Epoch 99/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.0436 - accuracy: 0.7200\n",
            "Epoch 99: loss did not improve from 1.04307\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.0436 - accuracy: 0.7200\n",
            "Epoch 100/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 1.0298 - accuracy: 0.7253\n",
            "Epoch 100: loss improved from 1.04307 to 1.03248, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0325 - accuracy: 0.7250\n",
            "Epoch 101/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 1.0264 - accuracy: 0.7238\n",
            "Epoch 101: loss improved from 1.03248 to 1.02542, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0254 - accuracy: 0.7241\n",
            "Epoch 102/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 1.0126 - accuracy: 0.7259\n",
            "Epoch 102: loss improved from 1.02542 to 1.01354, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.0135 - accuracy: 0.7258\n",
            "Epoch 103/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 1.0138 - accuracy: 0.7270\n",
            "Epoch 103: loss improved from 1.01354 to 1.01309, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 1.0131 - accuracy: 0.7271\n",
            "Epoch 104/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.7300\n",
            "Epoch 104: loss improved from 1.01309 to 1.00162, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 1.0016 - accuracy: 0.7300\n",
            "Epoch 105/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.9938 - accuracy: 0.7306\n",
            "Epoch 105: loss improved from 1.00162 to 0.99452, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9945 - accuracy: 0.7302\n",
            "Epoch 106/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.9879 - accuracy: 0.7308\n",
            "Epoch 106: loss improved from 0.99452 to 0.98729, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9873 - accuracy: 0.7310\n",
            "Epoch 107/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.9806 - accuracy: 0.7320\n",
            "Epoch 107: loss improved from 0.98729 to 0.98058, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.9806 - accuracy: 0.7320\n",
            "Epoch 108/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.9730 - accuracy: 0.7327\n",
            "Epoch 108: loss improved from 0.98058 to 0.97426, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.9743 - accuracy: 0.7327\n",
            "Epoch 109/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.7327\n",
            "Epoch 109: loss improved from 0.97426 to 0.97296, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9730 - accuracy: 0.7324\n",
            "Epoch 110/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.9651 - accuracy: 0.7342\n",
            "Epoch 110: loss improved from 0.97296 to 0.96538, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9654 - accuracy: 0.7342\n",
            "Epoch 111/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.9587 - accuracy: 0.7329\n",
            "Epoch 111: loss improved from 0.96538 to 0.95817, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9582 - accuracy: 0.7333\n",
            "Epoch 112/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.9516 - accuracy: 0.7366\n",
            "Epoch 112: loss improved from 0.95817 to 0.95162, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9516 - accuracy: 0.7366\n",
            "Epoch 113/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.9520 - accuracy: 0.7355\n",
            "Epoch 113: loss did not improve from 0.95162\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.9518 - accuracy: 0.7357\n",
            "Epoch 114/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.9336 - accuracy: 0.7392\n",
            "Epoch 114: loss improved from 0.95162 to 0.93339, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9334 - accuracy: 0.7392\n",
            "Epoch 115/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.9325 - accuracy: 0.7379\n",
            "Epoch 115: loss did not improve from 0.93339\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.9335 - accuracy: 0.7378\n",
            "Epoch 116/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.9356 - accuracy: 0.7363\n",
            "Epoch 116: loss did not improve from 0.93339\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9356 - accuracy: 0.7363\n",
            "Epoch 117/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.9199 - accuracy: 0.7398\n",
            "Epoch 117: loss improved from 0.93339 to 0.92057, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9206 - accuracy: 0.7396\n",
            "Epoch 118/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.9186 - accuracy: 0.7403\n",
            "Epoch 118: loss improved from 0.92057 to 0.92006, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9201 - accuracy: 0.7401\n",
            "Epoch 119/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.9113 - accuracy: 0.7426\n",
            "Epoch 119: loss improved from 0.92006 to 0.91133, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.9113 - accuracy: 0.7426\n",
            "Epoch 120/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.9103 - accuracy: 0.7413\n",
            "Epoch 120: loss improved from 0.91133 to 0.91035, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.9104 - accuracy: 0.7414\n",
            "Epoch 121/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.8959 - accuracy: 0.7440\n",
            "Epoch 121: loss improved from 0.91035 to 0.89588, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8959 - accuracy: 0.7440\n",
            "Epoch 122/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.8957 - accuracy: 0.7436\n",
            "Epoch 122: loss improved from 0.89588 to 0.89568, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8957 - accuracy: 0.7436\n",
            "Epoch 123/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.8891 - accuracy: 0.7461\n",
            "Epoch 123: loss improved from 0.89568 to 0.88927, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8893 - accuracy: 0.7462\n",
            "Epoch 124/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.8863 - accuracy: 0.7473\n",
            "Epoch 124: loss improved from 0.88927 to 0.88667, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8867 - accuracy: 0.7472\n",
            "Epoch 125/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.8791 - accuracy: 0.7488\n",
            "Epoch 125: loss improved from 0.88667 to 0.87921, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8792 - accuracy: 0.7488\n",
            "Epoch 126/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.8757 - accuracy: 0.7462\n",
            "Epoch 126: loss improved from 0.87921 to 0.87573, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8757 - accuracy: 0.7462\n",
            "Epoch 127/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.8742 - accuracy: 0.7514\n",
            "Epoch 127: loss did not improve from 0.87573\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8759 - accuracy: 0.7508\n",
            "Epoch 128/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.8672 - accuracy: 0.7475\n",
            "Epoch 128: loss improved from 0.87573 to 0.86638, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8664 - accuracy: 0.7479\n",
            "Epoch 129/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.8682 - accuracy: 0.7486\n",
            "Epoch 129: loss did not improve from 0.86638\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8682 - accuracy: 0.7486\n",
            "Epoch 130/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.8582 - accuracy: 0.7505\n",
            "Epoch 130: loss improved from 0.86638 to 0.85906, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8591 - accuracy: 0.7502\n",
            "Epoch 131/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.8544 - accuracy: 0.7541\n",
            "Epoch 131: loss improved from 0.85906 to 0.85581, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8558 - accuracy: 0.7537\n",
            "Epoch 132/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.8530 - accuracy: 0.7522\n",
            "Epoch 132: loss improved from 0.85581 to 0.85358, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8536 - accuracy: 0.7520\n",
            "Epoch 133/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.8445 - accuracy: 0.7537\n",
            "Epoch 133: loss improved from 0.85358 to 0.84521, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8452 - accuracy: 0.7535\n",
            "Epoch 134/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.8422 - accuracy: 0.7540\n",
            "Epoch 134: loss improved from 0.84521 to 0.84359, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8436 - accuracy: 0.7533\n",
            "Epoch 135/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.8382 - accuracy: 0.7544\n",
            "Epoch 135: loss improved from 0.84359 to 0.83873, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8387 - accuracy: 0.7544\n",
            "Epoch 136/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.8347 - accuracy: 0.7536\n",
            "Epoch 136: loss improved from 0.83873 to 0.83506, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8351 - accuracy: 0.7534\n",
            "Epoch 137/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.8349 - accuracy: 0.7534\n",
            "Epoch 137: loss did not improve from 0.83506\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8354 - accuracy: 0.7531\n",
            "Epoch 138/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.8238 - accuracy: 0.7557\n",
            "Epoch 138: loss improved from 0.83506 to 0.82628, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8263 - accuracy: 0.7551\n",
            "Epoch 139/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.8261 - accuracy: 0.7576\n",
            "Epoch 139: loss improved from 0.82628 to 0.82613, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8261 - accuracy: 0.7576\n",
            "Epoch 140/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.8259 - accuracy: 0.7563\n",
            "Epoch 140: loss improved from 0.82613 to 0.82589, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8259 - accuracy: 0.7563\n",
            "Epoch 141/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.8184 - accuracy: 0.7552\n",
            "Epoch 141: loss improved from 0.82589 to 0.81932, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8193 - accuracy: 0.7551\n",
            "Epoch 142/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.8142 - accuracy: 0.7548\n",
            "Epoch 142: loss improved from 0.81932 to 0.81418, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8142 - accuracy: 0.7548\n",
            "Epoch 143/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.8104 - accuracy: 0.7578\n",
            "Epoch 143: loss improved from 0.81418 to 0.81133, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8113 - accuracy: 0.7577\n",
            "Epoch 144/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.8049 - accuracy: 0.7594\n",
            "Epoch 144: loss improved from 0.81133 to 0.80508, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8051 - accuracy: 0.7593\n",
            "Epoch 145/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.8047 - accuracy: 0.7565\n",
            "Epoch 145: loss did not improve from 0.80508\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.8062 - accuracy: 0.7563\n",
            "Epoch 146/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.8037 - accuracy: 0.7580\n",
            "Epoch 146: loss improved from 0.80508 to 0.80409, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.8041 - accuracy: 0.7578\n",
            "Epoch 147/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.7986 - accuracy: 0.7609\n",
            "Epoch 147: loss improved from 0.80409 to 0.79853, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7985 - accuracy: 0.7610\n",
            "Epoch 148/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.7961 - accuracy: 0.7594\n",
            "Epoch 148: loss improved from 0.79853 to 0.79702, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7970 - accuracy: 0.7592\n",
            "Epoch 149/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7923 - accuracy: 0.7615\n",
            "Epoch 149: loss improved from 0.79702 to 0.79232, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7923 - accuracy: 0.7615\n",
            "Epoch 150/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.7881 - accuracy: 0.7619\n",
            "Epoch 150: loss improved from 0.79232 to 0.78911, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7891 - accuracy: 0.7615\n",
            "Epoch 151/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.7823 - accuracy: 0.7627\n",
            "Epoch 151: loss improved from 0.78911 to 0.78299, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7830 - accuracy: 0.7625\n",
            "Epoch 152/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7855 - accuracy: 0.7601\n",
            "Epoch 152: loss did not improve from 0.78299\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7855 - accuracy: 0.7601\n",
            "Epoch 153/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.7779 - accuracy: 0.7651\n",
            "Epoch 153: loss improved from 0.78299 to 0.77847, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7785 - accuracy: 0.7651\n",
            "Epoch 154/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.7850 - accuracy: 0.7601\n",
            "Epoch 154: loss did not improve from 0.77847\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7840 - accuracy: 0.7603\n",
            "Epoch 155/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7764 - accuracy: 0.7638\n",
            "Epoch 155: loss improved from 0.77847 to 0.77640, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7764 - accuracy: 0.7638\n",
            "Epoch 156/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.7645\n",
            "Epoch 156: loss improved from 0.77640 to 0.76919, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7692 - accuracy: 0.7645\n",
            "Epoch 157/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7708 - accuracy: 0.7622\n",
            "Epoch 157: loss did not improve from 0.76919\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7708 - accuracy: 0.7622\n",
            "Epoch 158/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.7681 - accuracy: 0.7655\n",
            "Epoch 158: loss improved from 0.76919 to 0.76827, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7683 - accuracy: 0.7653\n",
            "Epoch 159/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.7675 - accuracy: 0.7645\n",
            "Epoch 159: loss improved from 0.76827 to 0.76701, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7670 - accuracy: 0.7644\n",
            "Epoch 160/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.7598 - accuracy: 0.7666\n",
            "Epoch 160: loss improved from 0.76701 to 0.75983, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7598 - accuracy: 0.7666\n",
            "Epoch 161/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.7562 - accuracy: 0.7689\n",
            "Epoch 161: loss improved from 0.75983 to 0.75575, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7558 - accuracy: 0.7690\n",
            "Epoch 162/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.7574 - accuracy: 0.7662\n",
            "Epoch 162: loss did not improve from 0.75575\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7571 - accuracy: 0.7665\n",
            "Epoch 163/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.7554 - accuracy: 0.7658\n",
            "Epoch 163: loss improved from 0.75575 to 0.75529, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7553 - accuracy: 0.7658\n",
            "Epoch 164/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.7501 - accuracy: 0.7677\n",
            "Epoch 164: loss improved from 0.75529 to 0.74902, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7490 - accuracy: 0.7680\n",
            "Epoch 165/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.7448 - accuracy: 0.7685\n",
            "Epoch 165: loss improved from 0.74902 to 0.74704, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7470 - accuracy: 0.7679\n",
            "Epoch 166/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7543 - accuracy: 0.7651\n",
            "Epoch 166: loss did not improve from 0.74704\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7543 - accuracy: 0.7651\n",
            "Epoch 167/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.7434 - accuracy: 0.7707\n",
            "Epoch 167: loss improved from 0.74704 to 0.74329, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7433 - accuracy: 0.7709\n",
            "Epoch 168/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.7467 - accuracy: 0.7676\n",
            "Epoch 168: loss did not improve from 0.74329\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7471 - accuracy: 0.7674\n",
            "Epoch 169/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.7449 - accuracy: 0.7664\n",
            "Epoch 169: loss did not improve from 0.74329\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7442 - accuracy: 0.7669\n",
            "Epoch 170/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.7676\n",
            "Epoch 170: loss improved from 0.74329 to 0.73722, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 0.7372 - accuracy: 0.7676\n",
            "Epoch 171/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.7355 - accuracy: 0.7697\n",
            "Epoch 171: loss did not improve from 0.73722\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7376 - accuracy: 0.7695\n",
            "Epoch 172/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.7346 - accuracy: 0.7706\n",
            "Epoch 172: loss improved from 0.73722 to 0.73470, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7347 - accuracy: 0.7707\n",
            "Epoch 173/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.7339 - accuracy: 0.7700\n",
            "Epoch 173: loss improved from 0.73470 to 0.73391, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7339 - accuracy: 0.7700\n",
            "Epoch 174/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7265 - accuracy: 0.7709\n",
            "Epoch 174: loss improved from 0.73391 to 0.72647, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7265 - accuracy: 0.7709\n",
            "Epoch 175/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.7260 - accuracy: 0.7713\n",
            "Epoch 175: loss did not improve from 0.72647\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7268 - accuracy: 0.7712\n",
            "Epoch 176/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.7241 - accuracy: 0.7718\n",
            "Epoch 176: loss improved from 0.72647 to 0.72458, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7246 - accuracy: 0.7716\n",
            "Epoch 177/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.7200 - accuracy: 0.7711\n",
            "Epoch 177: loss improved from 0.72458 to 0.72004, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7200 - accuracy: 0.7712\n",
            "Epoch 178/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.7207 - accuracy: 0.7689\n",
            "Epoch 178: loss did not improve from 0.72004\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7207 - accuracy: 0.7689\n",
            "Epoch 179/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.7220 - accuracy: 0.7717\n",
            "Epoch 179: loss did not improve from 0.72004\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7217 - accuracy: 0.7717\n",
            "Epoch 180/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.7162 - accuracy: 0.7729\n",
            "Epoch 180: loss improved from 0.72004 to 0.71826, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7183 - accuracy: 0.7723\n",
            "Epoch 181/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.7168 - accuracy: 0.7735\n",
            "Epoch 181: loss improved from 0.71826 to 0.71671, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7167 - accuracy: 0.7735\n",
            "Epoch 182/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.7125 - accuracy: 0.7704\n",
            "Epoch 182: loss improved from 0.71671 to 0.71248, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7125 - accuracy: 0.7704\n",
            "Epoch 183/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.7112 - accuracy: 0.7727\n",
            "Epoch 183: loss improved from 0.71248 to 0.71197, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7120 - accuracy: 0.7727\n",
            "Epoch 184/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.7121 - accuracy: 0.7730\n",
            "Epoch 184: loss did not improve from 0.71197\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7123 - accuracy: 0.7729\n",
            "Epoch 185/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.7096 - accuracy: 0.7719\n",
            "Epoch 185: loss improved from 0.71197 to 0.70901, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7090 - accuracy: 0.7720\n",
            "Epoch 186/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.7064 - accuracy: 0.7727\n",
            "Epoch 186: loss improved from 0.70901 to 0.70630, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7063 - accuracy: 0.7727\n",
            "Epoch 187/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.7077 - accuracy: 0.7746\n",
            "Epoch 187: loss did not improve from 0.70630\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7083 - accuracy: 0.7742\n",
            "Epoch 188/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.7037 - accuracy: 0.7722\n",
            "Epoch 188: loss improved from 0.70630 to 0.70351, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7035 - accuracy: 0.7721\n",
            "Epoch 189/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.7769\n",
            "Epoch 189: loss improved from 0.70351 to 0.70211, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.7021 - accuracy: 0.7766\n",
            "Epoch 190/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.7050 - accuracy: 0.7751\n",
            "Epoch 190: loss did not improve from 0.70211\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.7050 - accuracy: 0.7751\n",
            "Epoch 191/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.7753\n",
            "Epoch 191: loss improved from 0.70211 to 0.69955, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6995 - accuracy: 0.7753\n",
            "Epoch 192/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6980 - accuracy: 0.7753\n",
            "Epoch 192: loss improved from 0.69955 to 0.69699, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6970 - accuracy: 0.7757\n",
            "Epoch 193/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.7750\n",
            "Epoch 193: loss improved from 0.69699 to 0.69332, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6933 - accuracy: 0.7748\n",
            "Epoch 194/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.7769\n",
            "Epoch 194: loss improved from 0.69332 to 0.69126, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6913 - accuracy: 0.7769\n",
            "Epoch 195/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.7731\n",
            "Epoch 195: loss did not improve from 0.69126\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6950 - accuracy: 0.7731\n",
            "Epoch 196/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6885 - accuracy: 0.7780\n",
            "Epoch 196: loss improved from 0.69126 to 0.68936, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6894 - accuracy: 0.7778\n",
            "Epoch 197/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6878 - accuracy: 0.7779\n",
            "Epoch 197: loss improved from 0.68936 to 0.68908, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6891 - accuracy: 0.7777\n",
            "Epoch 198/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.7796\n",
            "Epoch 198: loss improved from 0.68908 to 0.68462, saving model to model.h5\n",
            "254/254 [==============================] - 3s 10ms/step - loss: 0.6846 - accuracy: 0.7796\n",
            "Epoch 199/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.7772\n",
            "Epoch 199: loss did not improve from 0.68462\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6874 - accuracy: 0.7772\n",
            "Epoch 200/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.6873 - accuracy: 0.7768\n",
            "Epoch 200: loss did not improve from 0.68462\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6873 - accuracy: 0.7768\n",
            "Epoch 201/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6855 - accuracy: 0.7781\n",
            "Epoch 201: loss did not improve from 0.68462\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6852 - accuracy: 0.7779\n",
            "Epoch 202/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.7788\n",
            "Epoch 202: loss improved from 0.68462 to 0.68209, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6821 - accuracy: 0.7787\n",
            "Epoch 203/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.7768\n",
            "Epoch 203: loss did not improve from 0.68209\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6852 - accuracy: 0.7768\n",
            "Epoch 204/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.6750 - accuracy: 0.7806\n",
            "Epoch 204: loss improved from 0.68209 to 0.67612, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6761 - accuracy: 0.7807\n",
            "Epoch 205/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6746 - accuracy: 0.7766\n",
            "Epoch 205: loss improved from 0.67612 to 0.67461, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6746 - accuracy: 0.7767\n",
            "Epoch 206/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.7779\n",
            "Epoch 206: loss did not improve from 0.67461\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6771 - accuracy: 0.7778\n",
            "Epoch 207/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.6770 - accuracy: 0.7777\n",
            "Epoch 207: loss did not improve from 0.67461\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6780 - accuracy: 0.7772\n",
            "Epoch 208/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.7786\n",
            "Epoch 208: loss improved from 0.67461 to 0.67264, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6726 - accuracy: 0.7788\n",
            "Epoch 209/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6785 - accuracy: 0.7778\n",
            "Epoch 209: loss did not improve from 0.67264\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6775 - accuracy: 0.7780\n",
            "Epoch 210/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.7785\n",
            "Epoch 210: loss improved from 0.67264 to 0.66977, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6698 - accuracy: 0.7787\n",
            "Epoch 211/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.7799\n",
            "Epoch 211: loss did not improve from 0.66977\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6737 - accuracy: 0.7799\n",
            "Epoch 212/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.7769\n",
            "Epoch 212: loss did not improve from 0.66977\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6774 - accuracy: 0.7772\n",
            "Epoch 213/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6669 - accuracy: 0.7802\n",
            "Epoch 213: loss improved from 0.66977 to 0.66803, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6680 - accuracy: 0.7796\n",
            "Epoch 214/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.7795\n",
            "Epoch 214: loss did not improve from 0.66803\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6709 - accuracy: 0.7798\n",
            "Epoch 215/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.7780\n",
            "Epoch 215: loss did not improve from 0.66803\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6706 - accuracy: 0.7776\n",
            "Epoch 216/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.6648 - accuracy: 0.7786\n",
            "Epoch 216: loss improved from 0.66803 to 0.66497, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6650 - accuracy: 0.7785\n",
            "Epoch 217/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.7781\n",
            "Epoch 217: loss did not improve from 0.66497\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6658 - accuracy: 0.7781\n",
            "Epoch 218/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6608 - accuracy: 0.7802\n",
            "Epoch 218: loss improved from 0.66497 to 0.66178, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6618 - accuracy: 0.7800\n",
            "Epoch 219/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.6631 - accuracy: 0.7814\n",
            "Epoch 219: loss did not improve from 0.66178\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6623 - accuracy: 0.7815\n",
            "Epoch 220/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6573 - accuracy: 0.7809\n",
            "Epoch 220: loss improved from 0.66178 to 0.65754, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6575 - accuracy: 0.7809\n",
            "Epoch 221/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6630 - accuracy: 0.7809\n",
            "Epoch 221: loss did not improve from 0.65754\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6631 - accuracy: 0.7810\n",
            "Epoch 222/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6580 - accuracy: 0.7800\n",
            "Epoch 222: loss did not improve from 0.65754\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6577 - accuracy: 0.7802\n",
            "Epoch 223/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6602 - accuracy: 0.7815\n",
            "Epoch 223: loss did not improve from 0.65754\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6604 - accuracy: 0.7813\n",
            "Epoch 224/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.7807\n",
            "Epoch 224: loss did not improve from 0.65754\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6596 - accuracy: 0.7808\n",
            "Epoch 225/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6582 - accuracy: 0.7786\n",
            "Epoch 225: loss did not improve from 0.65754\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6579 - accuracy: 0.7787\n",
            "Epoch 226/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6557 - accuracy: 0.7802\n",
            "Epoch 226: loss improved from 0.65754 to 0.65638, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6564 - accuracy: 0.7801\n",
            "Epoch 227/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.6503 - accuracy: 0.7831\n",
            "Epoch 227: loss improved from 0.65638 to 0.65045, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6505 - accuracy: 0.7831\n",
            "Epoch 228/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6552 - accuracy: 0.7806\n",
            "Epoch 228: loss did not improve from 0.65045\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6545 - accuracy: 0.7809\n",
            "Epoch 229/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6451 - accuracy: 0.7827\n",
            "Epoch 229: loss improved from 0.65045 to 0.64538, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6454 - accuracy: 0.7825\n",
            "Epoch 230/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6522 - accuracy: 0.7799\n",
            "Epoch 230: loss did not improve from 0.64538\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6530 - accuracy: 0.7798\n",
            "Epoch 231/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.6480 - accuracy: 0.7833\n",
            "Epoch 231: loss did not improve from 0.64538\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6480 - accuracy: 0.7833\n",
            "Epoch 232/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.7821\n",
            "Epoch 232: loss did not improve from 0.64538\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6457 - accuracy: 0.7821\n",
            "Epoch 233/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6463 - accuracy: 0.7832\n",
            "Epoch 233: loss did not improve from 0.64538\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6461 - accuracy: 0.7831\n",
            "Epoch 234/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.6499 - accuracy: 0.7821\n",
            "Epoch 234: loss did not improve from 0.64538\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6500 - accuracy: 0.7821\n",
            "Epoch 235/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.7837\n",
            "Epoch 235: loss did not improve from 0.64538\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6477 - accuracy: 0.7836\n",
            "Epoch 236/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.6420 - accuracy: 0.7838\n",
            "Epoch 236: loss improved from 0.64538 to 0.64213, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6421 - accuracy: 0.7839\n",
            "Epoch 237/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6420 - accuracy: 0.7836\n",
            "Epoch 237: loss improved from 0.64213 to 0.64205, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6420 - accuracy: 0.7836\n",
            "Epoch 238/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.7829\n",
            "Epoch 238: loss did not improve from 0.64205\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6429 - accuracy: 0.7829\n",
            "Epoch 239/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.7839\n",
            "Epoch 239: loss did not improve from 0.64205\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6425 - accuracy: 0.7839\n",
            "Epoch 240/250\n",
            "253/254 [============================>.] - ETA: 0s - loss: 0.6422 - accuracy: 0.7830\n",
            "Epoch 240: loss improved from 0.64205 to 0.64203, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6420 - accuracy: 0.7831\n",
            "Epoch 241/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6374 - accuracy: 0.7850\n",
            "Epoch 241: loss improved from 0.64203 to 0.63844, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6384 - accuracy: 0.7848\n",
            "Epoch 242/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.7833\n",
            "Epoch 242: loss did not improve from 0.63844\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6395 - accuracy: 0.7831\n",
            "Epoch 243/250\n",
            "250/254 [============================>.] - ETA: 0s - loss: 0.6368 - accuracy: 0.7843\n",
            "Epoch 243: loss improved from 0.63844 to 0.63667, saving model to model.h5\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6367 - accuracy: 0.7842\n",
            "Epoch 244/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.6405 - accuracy: 0.7831\n",
            "Epoch 244: loss did not improve from 0.63667\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6400 - accuracy: 0.7835\n",
            "Epoch 245/250\n",
            "248/254 [============================>.] - ETA: 0s - loss: 0.6318 - accuracy: 0.7851\n",
            "Epoch 245: loss improved from 0.63667 to 0.63280, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6328 - accuracy: 0.7849\n",
            "Epoch 246/250\n",
            "252/254 [============================>.] - ETA: 0s - loss: 0.6348 - accuracy: 0.7830\n",
            "Epoch 246: loss did not improve from 0.63280\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6347 - accuracy: 0.7829\n",
            "Epoch 247/250\n",
            "254/254 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.7835\n",
            "Epoch 247: loss did not improve from 0.63280\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6348 - accuracy: 0.7835\n",
            "Epoch 248/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6392 - accuracy: 0.7846\n",
            "Epoch 248: loss did not improve from 0.63280\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6390 - accuracy: 0.7849\n",
            "Epoch 249/250\n",
            "251/254 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.7836\n",
            "Epoch 249: loss did not improve from 0.63280\n",
            "254/254 [==============================] - 2s 8ms/step - loss: 0.6381 - accuracy: 0.7836\n",
            "Epoch 250/250\n",
            "249/254 [============================>.] - ETA: 0s - loss: 0.6293 - accuracy: 0.7853\n",
            "Epoch 250: loss improved from 0.63280 to 0.63025, saving model to model.h5\n",
            "254/254 [==============================] - 2s 9ms/step - loss: 0.6302 - accuracy: 0.7849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Eğitim Sonuçlarını Görselleştirme\n",
        "\n",
        "Grafikler: Eğitim sürecindeki kayıp ve doğruluk değerlerini grafik olarak çizer."
      ],
      "metadata": {
        "id": "4eQOycBH1iER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.title('Eğitim Kaybı')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Kayıp')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.title('Eğitim Doğruluğu')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PRXZBJxR1icd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "3d694d9b-ac31-4ed8-9ea9-330438dc4313"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Tahmin Fonksiyonu\n",
        "\n",
        "generate_text: Girilen metni tamamlamak için modelin tahmin ettiği kelimeleri ekler."
      ],
      "metadata": {
        "id": "vL69U7cu1r_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, text, num_words_to_predict=1):\n",
        "    for _ in range(num_words_to_predict):\n",
        "        encoded = tokenizer.texts_to_sequences([text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length-1, padding='pre')\n",
        "\n",
        "        y_pred = model.predict(encoded, verbose=0)\n",
        "        predicted_word = tokenizer.index_word[np.argmax(y_pred)]\n",
        "\n",
        "        text += ' ' + predicted_word\n",
        "\n",
        "        if predicted_word == 'end':\n",
        "            break\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "_d8J0iT21sab"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Arayüz Bileşenleri\n",
        "\n",
        "Arayüz bileşenleri: Kullanıcı girişi ve modelin tahminlerini göstermek için arayüz bileşenleri oluşturulur.\n"
      ],
      "metadata": {
        "id": "y0WvzGnb10Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_box = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Eksik cümlenizi buraya yazın',\n",
        "    description='Cümle:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "output_label = widgets.Label(value='Tamamlanmış cümle burada görünecek')\n",
        "\n",
        "word_count_slider = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=10,\n",
        "    step=1,\n",
        "    description='Kelime Sayısı:',\n",
        "    continuous_update=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(\n",
        "    description='Tahmin Et',\n",
        "    disabled=False,\n",
        "    button_style='',\n",
        "    tooltip='Tahmin Et',\n",
        "    icon='check'\n",
        ")\n"
      ],
      "metadata": {
        "id": "HirBvFrH10nz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Buton Tıklama Olayı Ve Arayüzü Görüntüleme\n",
        "\n",
        "Buton olayı: Butona tıklandığında tahmin fonksiyonu çalıştırılır ve sonuç gösterilir\n",
        "\n",
        "Arayüzü göster: Arayüz bileşenlerini ekranda gösterir.\n"
      ],
      "metadata": {
        "id": "UfqpbcvH19eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def on_button_click(b):\n",
        "    input_text = text_box.value\n",
        "    num_words_to_predict = word_count_slider.value\n",
        "    if input_text.strip():\n",
        "        completed_text = generate_text(model, tokenizer, input_text, num_words_to_predict)\n",
        "        output_label.value = f\"Tahmin Edilen Cümle: {completed_text}\"\n",
        "        text_box.value = completed_text\n",
        "\n",
        "button.on_click(on_button_click)\n",
        "\n",
        "# Arayüzü görüntüle\n",
        "display(text_box, word_count_slider, button, output_label)\n"
      ],
      "metadata": {
        "id": "CLM-gzoF190F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "fde54c76fc144f21863fd616fc1397e0",
            "8fabbd02d57a4c10818144a40c3e0ca5",
            "b64190f95c1f41ffa1a9c1a21e7bd934",
            "623be7b98a284997873d8dc172244b21",
            "4f4d218645954c3d8b4121e0ad328781",
            "0758caa8d240447ca03acd73034261d0",
            "48926711156f4bbc89e9b365a13e0ebb",
            "163d81b3820242ecbc3d8446a8233dbc",
            "0124f550372b4c3aafe3021e258bc266",
            "0f55cb2f92e14c9792fe1194b9d041e6",
            "855fa549684842e1ab541dab877c8f23",
            "a5a89274913d4c0581df1afcc9ec27d3"
          ]
        },
        "outputId": "41758ec5-2100-48de-cddd-7c64d49db72b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Cümle:', placeholder='Eksik cümlenizi buraya yazın')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fde54c76fc144f21863fd616fc1397e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=1, continuous_update=False, description='Kelime Sayısı:', max=10, min=1)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "623be7b98a284997873d8dc172244b21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Tahmin Et', icon='check', style=ButtonStyle(), tooltip='Tahmin Et')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48926711156f4bbc89e9b365a13e0ebb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Label(value='Tamamlanmış cümle burada görünecek')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f55cb2f92e14c9792fe1194b9d041e6"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}